{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b186b4bb",
   "metadata": {},
   "source": [
    "3차 다항식(third order polynomial)을 사용하여 y=$sin(x)$ 에 근사(fit)하는 문제를 다뤄보겠습니다. 신경망은 4개의 매개변수를 가지며, 정답과 신경망이 예측한 결과 사이의 유클리드 거리(Euclidean distance)를 최소화하여 임의의 값을 근사할 수 있도록 경사하강법(gradient descent)을 사용하여 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58231956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 2932.532119601867\n",
      "199 1986.2864742160687\n",
      "299 1347.670787848512\n",
      "399 916.2497464753031\n",
      "499 624.507163867261\n",
      "599 427.0171040012009\n",
      "699 293.1890901809671\n",
      "799 202.40413715516607\n",
      "899 140.75122545565745\n",
      "999 98.83587481223249\n",
      "1099 70.30741339504765\n",
      "1199 50.86839866003989\n",
      "1299 37.60775364294483\n",
      "1399 28.551422427313526\n",
      "1499 22.359310296823786\n",
      "1599 18.120688477379243\n",
      "1699 15.215935548177704\n",
      "1799 13.223012236658677\n",
      "1899 11.854130591726099\n",
      "1999 10.912823991835229\n",
      "Result: y = -0.03865737475457288 + 0.8299095808833444 x + 0.006669040406656332 x^2 + -0.08951387564269557 x^3\n"
     ]
    }
   ],
   "source": [
    "# numpy를 통해 신경망 구축 \n",
    "\n",
    "import numpy as np\n",
    "import math \n",
    "\n",
    "# 무작위로 입력과 출력 데이터 생성 \n",
    "\n",
    "x = np.linspace(-math.pi, math.pi, 2000)\n",
    "y = np.sin(x)\n",
    "\n",
    "# 무작위로 가중치 초기화\n",
    "a = np.random.randn()\n",
    "b = np.random.randn()\n",
    "c = np.random.randn()\n",
    "d = np.random.randn()\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000) :\n",
    "    # 순전파 단계 예측값 계산 \n",
    "    # y = a + b x + c x^2 + d x^3\n",
    "    y_pred = a + b*x + c* x ** 2 + d *x **3\n",
    "    \n",
    "    # loss 계산 \n",
    "    loss = np.square(y_pred -y).sum()\n",
    "    if t % 100 ==99 :\n",
    "        print(t, loss)\n",
    "        \n",
    "    # loss에 따른 a,b,c,d의 변화도를 계산하고 역전파 \n",
    "    grad_y_pred = 2.0* (y_pred -y)\n",
    "    grad_a = grad_y_pred.sum()\n",
    "    grad_b = (grad_y_pred * x).sum()\n",
    "    grad_c = (grad_y_pred * x ** 2).sum()\n",
    "    grad_d = (grad_y_pred * x ** 3).sum()\n",
    "\n",
    "    # 가중치를 갱신합니다.\n",
    "    a -= learning_rate * grad_a\n",
    "    b -= learning_rate * grad_b\n",
    "    c -= learning_rate * grad_c\n",
    "    d -= learning_rate * grad_d\n",
    "\n",
    "print(f'Result: y = {a} + {b} x + {c} x^2 + {d} x^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "039e756b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 918.99267578125\n",
      "199 643.1675415039062\n",
      "299 451.278076171875\n",
      "399 317.66790771484375\n",
      "499 224.56072998046875\n",
      "599 159.6270751953125\n",
      "699 114.3072280883789\n",
      "799 82.65354919433594\n",
      "899 60.52942657470703\n",
      "999 45.05559539794922\n",
      "1099 34.22602081298828\n",
      "1199 26.642215728759766\n",
      "1299 21.328210830688477\n",
      "1399 17.60262107849121\n",
      "1499 14.989233016967773\n",
      "1599 13.155094146728516\n",
      "1699 11.867243766784668\n",
      "1799 10.962565422058105\n",
      "1899 10.326764106750488\n",
      "1999 9.879744529724121\n",
      "Result: y = 0.03316112980246544 + 0.8479872345924377 x + -0.005720846820622683 x^2 + -0.09208526462316513 x^3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda:0\") # GPU에서 실행하려면 이 주석을 제거하세요\n",
    "\n",
    "# 무작위로 입력과 출력 데이터를 생성합니다\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# 무작위로 가중치를 초기화합니다\n",
    "a = torch.randn((), device=device, dtype=dtype)\n",
    "b = torch.randn((), device=device, dtype=dtype)\n",
    "c = torch.randn((), device=device, dtype=dtype)\n",
    "d = torch.randn((), device=device, dtype=dtype)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    # 순전파 단계: 예측값 y를 계산합니다\n",
    "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "    # 손실(loss)을 계산하고 출력합니다\n",
    "    loss = (y_pred - y).pow(2).sum().item()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss)\n",
    "\n",
    "    # 손실에 따른 a, b, c, d의 변화도(gradient)를 계산하고 역전파합니다.\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_a = grad_y_pred.sum()\n",
    "    grad_b = (grad_y_pred * x).sum()\n",
    "    grad_c = (grad_y_pred * x ** 2).sum()\n",
    "    grad_d = (grad_y_pred * x ** 3).sum()\n",
    "\n",
    "    # 가중치를 갱신합니다.\n",
    "    a -= learning_rate * grad_a\n",
    "    b -= learning_rate * grad_b\n",
    "    c -= learning_rate * grad_c\n",
    "    d -= learning_rate * grad_d\n",
    "\n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62b3b44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 76.56168365478516\n",
      "199 56.52638244628906\n",
      "299 42.42686080932617\n",
      "399 32.50070571899414\n",
      "499 25.510486602783203\n",
      "599 20.58633804321289\n",
      "699 17.116626739501953\n",
      "799 14.671102523803711\n",
      "899 12.94703197479248\n",
      "999 11.731285095214844\n",
      "1099 10.873804092407227\n",
      "1199 10.268880844116211\n",
      "1299 9.842055320739746\n",
      "1399 9.540827751159668\n",
      "1499 9.328204154968262\n",
      "1599 9.178104400634766\n",
      "1699 9.072122573852539\n",
      "1799 8.99728012084961\n",
      "1899 8.944422721862793\n",
      "1999 8.907085418701172\n",
      "Result: y = -0.009929759427905083 + 0.8553959131240845 x + 0.0017130509950220585 x^2 + -0.09313908219337463 x^3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda:0\") # GPU에서 실행하려면 이 주석을 제거하세요\n",
    "\n",
    "# 입력값과 출력값을 갖는 텐서들을 생성합니다.\n",
    "# requires_grad=False가 기본값으로 설정되어 역전파 단계 중에 이 텐서들에 대한 변화도를\n",
    "# 계산할 필요가 없음을 나타냅니다.\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# 가중치를 갖는 임의의 텐서를 생성합니다. 3차 다항식이므로 4개의 가중치가 필요합니다:\n",
    "# y = a + b x + c x^2 + d x^3\n",
    "# requires_grad=True로 설정하여 역전파 단계 중에 이 텐서들에 대한 변화도를 계산할 필요가\n",
    "# 있음을 나타냅니다.\n",
    "a = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
    "b = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
    "c = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
    "d = torch.randn((), device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    # 순전파 단계: 텐서들 간의 연산을 사용하여 예측값 y를 계산합니다.\n",
    "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "    # 텐서들간의 연산을 사용하여 손실(loss)을 계싼하고 출력합니다.\n",
    "    # 이 때 손실은 (1,) shape을 갖는 텐서입니다.\n",
    "    # loss.item() 으로 손실이 갖고 있는 스칼라 값을 가져올 수 있습니다.\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # autograd 를 사용하여 역전파 단계를 계산합니다. 이는 requires_grad=True를 갖는\n",
    "    # 모든 텐서들에 대한 손실의 변화도를 계산합니다.\n",
    "    # 이후 a.grad와 b.grad, c.grad, d.grad는 각각 a, b, c, d에 대한 손실의 변화도를\n",
    "    # 갖는 텐서가 됩니다.\n",
    "    loss.backward()\n",
    "\n",
    "    # 경사하강법(gradient descent)를 사용하여 가중치를 직접 갱신합니다.\n",
    "    # torch.no_grad()로 감싸는 이유는, 가중치들이 requires_grad=True 지만\n",
    "    # autograd에서는 이를 추적하지 않을 것이기 때문입니다.\n",
    "    with torch.no_grad():\n",
    "        a -= learning_rate * a.grad\n",
    "        b -= learning_rate * b.grad\n",
    "        c -= learning_rate * c.grad\n",
    "        d -= learning_rate * d.grad\n",
    "\n",
    "        # 가중치 갱신 후에는 변화도를 직접 0으로 만듭니다.\n",
    "        a.grad = None\n",
    "        b.grad = None\n",
    "        c.grad = None\n",
    "        d.grad = None\n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
